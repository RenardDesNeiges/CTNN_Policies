{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example notebook for supervised training of LTC cells for time-series prediction tasks\n",
    "#### *(using the Pytorch implementation)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.agents.ppo import PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-07 17:51:41,672\tWARNING trainer.py:2279 -- You have specified 1 evaluation workers, but your `evaluation_interval` is None! Therefore, evaluation will not occur automatically with each call to `Trainer.train()`. Instead, you will have to call `Trainer.evaluate()` manually in order to trigger an evaluation run.\n",
      "\u001b[2m\u001b[36m(pid=73403)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=73404)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m 2022-03-07 17:51:51,457\tERROR worker.py:432 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=73403, ip=127.0.0.1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m   File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 460, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m     self.env = env_creator(copy.deepcopy(self.env_context))\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m   File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/env/utils.py\", line 52, in gym_env_creator\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m     return gym.make(env_descriptor, **env_context)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m   File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/registration.py\", line 676, in make\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m     return registry.make(id, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m   File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/registration.py\", line 520, in make\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m     return spec.make(**kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m   File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/registration.py\", line 139, in make\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m     cls = load(self.entry_point)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m   File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/registration.py\", line 55, in load\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m     mod = importlib.import_module(mod_name)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m   File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/importlib/__init__.py\", line 127, in import_module\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m     return _bootstrap._gcd_import(name[level:], package, level)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m   File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m   File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m   File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m   File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m   File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m   File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/toy_text/__init__.py\", line 1, in <module>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m     from gym.envs.toy_text.blackjack import BlackjackEnv\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m   File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/toy_text/blackjack.py\", line 5, in <module>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m     import pygame\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73403)\u001b[0m ModuleNotFoundError: No module named 'pygame'\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m 2022-03-07 17:51:51,457\tERROR worker.py:432 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=73404, ip=127.0.0.1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m   File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 460, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m     self.env = env_creator(copy.deepcopy(self.env_context))\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m   File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/env/utils.py\", line 52, in gym_env_creator\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m     return gym.make(env_descriptor, **env_context)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m   File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/registration.py\", line 676, in make\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m     return registry.make(id, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m   File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/registration.py\", line 520, in make\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m     return spec.make(**kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m   File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/registration.py\", line 139, in make\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m     cls = load(self.entry_point)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m   File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/registration.py\", line 55, in load\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m     mod = importlib.import_module(mod_name)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m   File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/importlib/__init__.py\", line 127, in import_module\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m     return _bootstrap._gcd_import(name[level:], package, level)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m   File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m   File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m   File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m   File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m   File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m   File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/toy_text/__init__.py\", line 1, in <module>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m     from gym.envs.toy_text.blackjack import BlackjackEnv\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m   File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/toy_text/blackjack.py\", line 5, in <module>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m     import pygame\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=73404)\u001b[0m ModuleNotFoundError: No module named 'pygame'\n"
     ]
    },
    {
     "ename": "RayActorError",
     "evalue": "The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=73404, ip=127.0.0.1)\n  File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 460, in __init__\n    self.env = env_creator(copy.deepcopy(self.env_context))\n  File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/env/utils.py\", line 52, in gym_env_creator\n    return gym.make(env_descriptor, **env_context)\n  File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/registration.py\", line 676, in make\n    return registry.make(id, **kwargs)\n  File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/registration.py\", line 520, in make\n    return spec.make(**kwargs)\n  File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/registration.py\", line 139, in make\n    cls = load(self.entry_point)\n  File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/registration.py\", line 55, in load\n    mod = importlib.import_module(mod_name)\n  File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/importlib/__init__.py\", line 127, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n  File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/toy_text/__init__.py\", line 1, in <module>\n    from gym.envs.toy_text.blackjack import BlackjackEnv\n  File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/toy_text/blackjack.py\", line 5, in <module>\n    import pygame\nModuleNotFoundError: No module named 'pygame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py:811\u001b[0m, in \u001b[0;36mTrainer.setup\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=809'>810</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=810'>811</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv_creator)\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=811'>812</a>\u001b[0m \u001b[39m# New design: Override `Trainable.setup()` (as indented by Trainable)\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=812'>813</a>\u001b[0m \u001b[39m# and do or don't call super().setup() from within your override.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=813'>814</a>\u001b[0m \u001b[39m# By default, `super().setup()` will create both worker sets:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=816'>817</a>\u001b[0m \u001b[39m# parallel to training.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=817'>818</a>\u001b[0m \u001b[39m# TODO: Deprecate `_init()` and remove this try/except block.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py:923\u001b[0m, in \u001b[0;36mTrainer._init\u001b[0;34m(self, config, env_creator)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=920'>921</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_init\u001b[39m(\u001b[39mself\u001b[39m, config: TrainerConfigDict,\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=921'>922</a>\u001b[0m           env_creator: Callable[[EnvContext], EnvType]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=922'>923</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRayActorError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/renard/Documents/etudes/EPFLMA4/LTC/code/ray_RLLIB_example.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/renard/Documents/etudes/EPFLMA4/LTC/code/ray_RLLIB_example.ipynb#ch0000024?line=1'>2</a>\u001b[0m config \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/renard/Documents/etudes/EPFLMA4/LTC/code/ray_RLLIB_example.ipynb#ch0000024?line=2'>3</a>\u001b[0m     \u001b[39m# Environment (RLlib understands openAI gym registered strings).\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/renard/Documents/etudes/EPFLMA4/LTC/code/ray_RLLIB_example.ipynb#ch0000024?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39menv\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mTaxi-v3\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/renard/Documents/etudes/EPFLMA4/LTC/code/ray_RLLIB_example.ipynb#ch0000024?line=22'>23</a>\u001b[0m     }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/renard/Documents/etudes/EPFLMA4/LTC/code/ray_RLLIB_example.ipynb#ch0000024?line=23'>24</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/renard/Documents/etudes/EPFLMA4/LTC/code/ray_RLLIB_example.ipynb#ch0000024?line=25'>26</a>\u001b[0m \u001b[39m# Create our RLlib Trainer.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/renard/Documents/etudes/EPFLMA4/LTC/code/ray_RLLIB_example.ipynb#ch0000024?line=26'>27</a>\u001b[0m trainer \u001b[39m=\u001b[39m PPOTrainer(config\u001b[39m=\u001b[39;49mconfig)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/renard/Documents/etudes/EPFLMA4/LTC/code/ray_RLLIB_example.ipynb#ch0000024?line=28'>29</a>\u001b[0m \u001b[39m# Run it for n training iterations. A training iteration includes\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/renard/Documents/etudes/EPFLMA4/LTC/code/ray_RLLIB_example.ipynb#ch0000024?line=29'>30</a>\u001b[0m \u001b[39m# parallel sample collection by the environment workers as well as\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/renard/Documents/etudes/EPFLMA4/LTC/code/ray_RLLIB_example.ipynb#ch0000024?line=30'>31</a>\u001b[0m \u001b[39m# loss calculation on the collected batch and a model update.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/renard/Documents/etudes/EPFLMA4/LTC/code/ray_RLLIB_example.ipynb#ch0000024?line=31'>32</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py:728\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, config, env, logger_creator, remote_checkpoint_dir, sync_function_tpl)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=724'>725</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_workers \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=725'>726</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_metrics \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=727'>728</a>\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(config, logger_creator, remote_checkpoint_dir,\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=728'>729</a>\u001b[0m                  sync_function_tpl)\n",
      "File \u001b[0;32m~/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/tune/trainable.py:122\u001b[0m, in \u001b[0;36mTrainable.__init__\u001b[0;34m(self, config, logger_creator, remote_checkpoint_dir, sync_function_tpl)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/tune/trainable.py?line=119'>120</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/tune/trainable.py?line=120'>121</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_ip \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_current_ip()\n\u001b[0;32m--> <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/tune/trainable.py?line=121'>122</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup(copy\u001b[39m.\u001b[39;49mdeepcopy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig))\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/tune/trainable.py?line=122'>123</a>\u001b[0m setup_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/tune/trainable.py?line=123'>124</a>\u001b[0m \u001b[39mif\u001b[39;00m setup_time \u001b[39m>\u001b[39m SETUP_TIME_THRESHOLD:\n",
      "File \u001b[0;32m~/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py:826\u001b[0m, in \u001b[0;36mTrainer.setup\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=811'>812</a>\u001b[0m \u001b[39m# New design: Override `Trainable.setup()` (as indented by Trainable)\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=812'>813</a>\u001b[0m \u001b[39m# and do or don't call super().setup() from within your override.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=813'>814</a>\u001b[0m \u001b[39m# By default, `super().setup()` will create both worker sets:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=816'>817</a>\u001b[0m \u001b[39m# parallel to training.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=817'>818</a>\u001b[0m \u001b[39m# TODO: Deprecate `_init()` and remove this try/except block.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=818'>819</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=819'>820</a>\u001b[0m     \u001b[39m# Only if user did not override `_init()`:\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=820'>821</a>\u001b[0m     \u001b[39m# - Create rollout workers here automatically.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=823'>824</a>\u001b[0m     \u001b[39m# This matches the behavior of using `build_trainer()`, which\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=824'>825</a>\u001b[0m     \u001b[39m# should no longer be used.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=825'>826</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_workers(\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=826'>827</a>\u001b[0m         env_creator\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv_creator,\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=827'>828</a>\u001b[0m         validate_env\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalidate_env,\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=828'>829</a>\u001b[0m         policy_class\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_default_policy_class(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig),\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=829'>830</a>\u001b[0m         config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig,\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=830'>831</a>\u001b[0m         num_workers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mnum_workers\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=832'>833</a>\u001b[0m     \u001b[39m# Function defining one single training iteration's behavior.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=833'>834</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39m_disable_execution_plan_api\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=834'>835</a>\u001b[0m         \u001b[39m# Ensure remote workers are initially in sync with the\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=835'>836</a>\u001b[0m         \u001b[39m# local worker.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py:1925\u001b[0m, in \u001b[0;36mTrainer._make_workers\u001b[0;34m(self, env_creator, validate_env, policy_class, config, num_workers, local_worker)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1888'>1889</a>\u001b[0m \u001b[39m@DeveloperAPI\u001b[39m\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1889'>1890</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_workers\u001b[39m(\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1890'>1891</a>\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1897'>1898</a>\u001b[0m         local_worker: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1898'>1899</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m WorkerSet:\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1899'>1900</a>\u001b[0m     \u001b[39m\"\"\"Default factory method for a WorkerSet running under this Trainer.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1900'>1901</a>\u001b[0m \n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1901'>1902</a>\u001b[0m \u001b[39m    Override this method by passing a custom `make_workers` into\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1922'>1923</a>\u001b[0m \u001b[39m        The created WorkerSet.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1923'>1924</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1924'>1925</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m WorkerSet(\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1925'>1926</a>\u001b[0m         env_creator\u001b[39m=\u001b[39;49menv_creator,\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1926'>1927</a>\u001b[0m         validate_env\u001b[39m=\u001b[39;49mvalidate_env,\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1927'>1928</a>\u001b[0m         policy_class\u001b[39m=\u001b[39;49mpolicy_class,\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1928'>1929</a>\u001b[0m         trainer_config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1929'>1930</a>\u001b[0m         num_workers\u001b[39m=\u001b[39;49mnum_workers,\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1930'>1931</a>\u001b[0m         local_worker\u001b[39m=\u001b[39;49mlocal_worker,\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1931'>1932</a>\u001b[0m         logdir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogdir,\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1932'>1933</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py:100\u001b[0m, in \u001b[0;36mWorkerSet.__init__\u001b[0;34m(self, env_creator, validate_env, policy_class, trainer_config, num_workers, local_worker, logdir, _setup)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py?line=91'>92</a>\u001b[0m \u001b[39m# Create a local worker, if needed.\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py?line=92'>93</a>\u001b[0m \u001b[39m# If num_workers > 0 and we don't have an env on the local worker,\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py?line=93'>94</a>\u001b[0m \u001b[39m# get the observation- and action spaces for each policy from\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py?line=94'>95</a>\u001b[0m \u001b[39m# the first remote worker (which does have an env).\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py?line=95'>96</a>\u001b[0m \u001b[39mif\u001b[39;00m local_worker \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_remote_workers \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m     <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py?line=96'>97</a>\u001b[0m         \u001b[39mnot\u001b[39;00m trainer_config\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcreate_env_on_driver\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m     <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py?line=97'>98</a>\u001b[0m         (\u001b[39mnot\u001b[39;00m trainer_config\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mobservation_space\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py?line=98'>99</a>\u001b[0m          \u001b[39mnot\u001b[39;00m trainer_config\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39maction_space\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[0;32m--> <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py?line=99'>100</a>\u001b[0m     remote_spaces \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39;49mget(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mremote_workers(\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py?line=100'>101</a>\u001b[0m     )[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mforeach_policy\u001b[39m.\u001b[39;49mremote(\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py?line=101'>102</a>\u001b[0m         \u001b[39mlambda\u001b[39;49;00m p, pid: (pid, p\u001b[39m.\u001b[39;49mobservation_space, p\u001b[39m.\u001b[39;49maction_space)))\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py?line=102'>103</a>\u001b[0m     spaces \u001b[39m=\u001b[39m {\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py?line=103'>104</a>\u001b[0m         e[\u001b[39m0\u001b[39m]: (\u001b[39mgetattr\u001b[39m(e[\u001b[39m1\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39moriginal_space\u001b[39m\u001b[39m\"\u001b[39m, e[\u001b[39m1\u001b[39m]), e[\u001b[39m2\u001b[39m])\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py?line=104'>105</a>\u001b[0m         \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m remote_spaces\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py?line=105'>106</a>\u001b[0m     }\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py?line=106'>107</a>\u001b[0m     \u001b[39m# Try to add the actual env's obs/action spaces.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/_private/client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/_private/client_mode_hook.py?line=102'>103</a>\u001b[0m     \u001b[39mif\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/_private/client_mode_hook.py?line=103'>104</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(ray, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/_private/client_mode_hook.py?line=104'>105</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/worker.py:1735\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/worker.py?line=1732'>1733</a>\u001b[0m             \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mas_instanceof_cause()\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/worker.py?line=1733'>1734</a>\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/worker.py?line=1734'>1735</a>\u001b[0m             \u001b[39mraise\u001b[39;00m value\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/worker.py?line=1736'>1737</a>\u001b[0m \u001b[39mif\u001b[39;00m is_individual_id:\n\u001b[1;32m   <a href='file:///Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/worker.py?line=1737'>1738</a>\u001b[0m     values \u001b[39m=\u001b[39m values[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mRayActorError\u001b[0m: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=73404, ip=127.0.0.1)\n  File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 460, in __init__\n    self.env = env_creator(copy.deepcopy(self.env_context))\n  File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/ray/rllib/env/utils.py\", line 52, in gym_env_creator\n    return gym.make(env_descriptor, **env_context)\n  File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/registration.py\", line 676, in make\n    return registry.make(id, **kwargs)\n  File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/registration.py\", line 520, in make\n    return spec.make(**kwargs)\n  File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/registration.py\", line 139, in make\n    cls = load(self.entry_point)\n  File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/registration.py\", line 55, in load\n    mod = importlib.import_module(mod_name)\n  File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/importlib/__init__.py\", line 127, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n  File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/toy_text/__init__.py\", line 1, in <module>\n    from gym.envs.toy_text.blackjack import BlackjackEnv\n  File \"/Users/renard/miniconda3/envs/torchLTC/lib/python3.8/site-packages/gym/envs/toy_text/blackjack.py\", line 5, in <module>\n    import pygame\nModuleNotFoundError: No module named 'pygame'"
     ]
    }
   ],
   "source": [
    "# Configure the algorithm.\n",
    "config = {\n",
    "    # Environment (RLlib understands openAI gym registered strings).\n",
    "    \"env\": \"Taxi-v3\",\n",
    "    # Use 2 environment workers (aka \"rollout workers\") that parallelly\n",
    "    # collect samples from their own environment clone(s).\n",
    "    \"num_workers\": 2,\n",
    "    # Change this to \"framework: torch\", if you are using PyTorch.\n",
    "    # Also, use \"framework: tf2\" for tf2.x eager execution.\n",
    "    \"framework\": \"tf\",\n",
    "    # Tweak the default model provided automatically by RLlib,\n",
    "    # given the environment's observation- and action spaces.\n",
    "    \"model\": {\n",
    "        \"fcnet_hiddens\": [64, 64],\n",
    "        \"fcnet_activation\": \"relu\",\n",
    "    },\n",
    "    # Set up a separate evaluation worker set for the\n",
    "    # `trainer.evaluate()` call after training (see below).\n",
    "    \"evaluation_num_workers\": 1,\n",
    "    # Only for evaluation runs, render the env.\n",
    "    \"evaluation_config\": {\n",
    "        \"render_env\": True,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create our RLlib Trainer.\n",
    "trainer = PPOTrainer(config=config)\n",
    "\n",
    "# Run it for n training iterations. A training iteration includes\n",
    "# parallel sample collection by the environment workers as well as\n",
    "# loss calculation on the collected batch and a model update.\n",
    "for _ in range(3):\n",
    "    print(trainer.train())\n",
    "\n",
    "# Evaluate the trained Trainer (and render each timestep to the shell's\n",
    "# output).\n",
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8fdc6dd3a09dc5c83aad34f80e2b308d8dfb410ffac43971d3f03fb3420545d"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('torchNCP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
